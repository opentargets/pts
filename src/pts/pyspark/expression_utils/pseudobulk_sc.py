import numpy as np
import pandas as pd
import scanpy as sc
from loguru import logger
from pyspark.sql.types import DoubleType, IntegerType, StringType, StructField, StructType


class PseudobulkExpression:
    """Process cellxgene formatted single-cell AnnData into pseudobulked JSON.

    This class reads an AnnData object, filters it, normalizes it,
    and then aggregates the data into pseudobulk format.
    """

    @property
    def flat_schema(self):
        # the schema for the FLAT pandas slice before we do the Spark grouping
        return StructType([
            StructField('targetId', StringType(), True),
            StructField('datasourceId', StringType(), True),
            StructField('datatypeId', StringType(), True),
            StructField('unit', StringType(), True),
            StructField('tissueBiosampleId', StringType(), True),
            StructField('tissueBiosampleFromSource', StringType(), True),
            StructField('celltypeBiosampleId', StringType(), True),
            StructField('celltypeBiosampleFromSource', StringType(), True),
            StructField('expression', DoubleType(), True),
            StructField('donorId', StringType(), True),
            StructField('cellCount', IntegerType(), True),
            StructField('sex', StringType(), True),
            StructField('age', StringType(), True),
            StructField('ethnicity', StringType(), True),
        ])

    def __init__(self, spark, h5ad_path, datasource_id, datatype_id, output_directory_path, json):
        self.spark = spark
        self.h5ad_path = h5ad_path
        self.datasource_id = datasource_id
        self.datatype_id = datatype_id
        self.output_directory_path = output_directory_path
        self.json = json

    def read_h5ad(self):
        logger.info(f'Reading h5ad file: {self.h5ad_path}')
        self.adata = sc.read(self.h5ad_path)
        self.adata.var_names_make_unique()
        self.adata.strings_to_categoricals()
        if self.adata.var.index.name != 'ensg':
            raise ValueError(f"Expected var index name 'ensg', got '{self.adata.var.index.name}'")

    def filter_anndata(self, min_cells=0, min_genes=0, technology='10X'):
        if min_genes > 0:
            sc.pp.filter_cells(self.adata, min_genes=min_genes)
        if min_cells > 0:
            sc.pp.filter_genes(self.adata, min_cells=min_cells)
        logger.info(f'Keeping only cells generated by {technology}')
        self.adata = self.adata[self.adata.obs['method'] == technology]

    def normalise_anndata(self):
        """Normalise the AnnData object using logCP10K method."""
        logger.info('Normalising data using logCP10K')
        # Check that the .X layer is truly counts by checking if the sum of one column is an integer
        if not np.sum(self.adata.X[:, 0]) % 1 == 0:
            raise ValueError('The .X layer is not truly counts')
        sc.pp.normalize_total(self.adata, target_sum=1e4)
        sc.pp.log1p(self.adata)

    def normalise_counts(self, counts_vector):
        """Normalise a vector of summed counts using CPM method.

        Parameters
        ----------
        counts_vector : pandas.Series
            Vector of summed counts to normalize

        Returns:
        -------
        pandas.Series
            Normalized counts vector (CPM)
        """
        # Convert to counts per million
        total_counts = counts_vector.sum()
        if total_counts > 0:
            return (counts_vector / total_counts) * 1e6
        else:
            return counts_vector

    def pseudobulk_data(self, donor_colname='donor_id', min_cells=5,
                        tissue_agg_colname=None, celltype_agg_colname=None,
                        agg_method='mean', age_colname='age', sex_colname='sex', ethnicity_colname='ethnicity'):
        adata = self.adata

        if tissue_agg_colname and celltype_agg_colname:
            annotations = adata.obs[[tissue_agg_colname, celltype_agg_colname]].drop_duplicates()
            annotations = [(row[tissue_agg_colname], row[celltype_agg_colname]) for _, row in annotations.iterrows()]
        elif tissue_agg_colname:
            annotations = [(tissue, None) for tissue in adata.obs[tissue_agg_colname].unique()]
        elif celltype_agg_colname:
            annotations = [(None, celltype) for celltype in adata.obs[celltype_agg_colname].unique()]
        else:
            raise ValueError('Provide at least one aggregation column.')

        # define a single output directory for this whole aggregation
        if self.json:
            output_dir = f'{self.output_directory_path}/json'
        else:
            output_dir = f'{self.output_directory_path}/parquet'

        for tissue_id, celltype_id in annotations:
            logger.info(f'Aggregating tissue={tissue_id}, celltype={celltype_id}')

            subset = adata
            if tissue_id:
                subset = subset[subset.obs[tissue_agg_colname] == tissue_id]
            if celltype_id:
                subset = subset[subset.obs[celltype_agg_colname] == celltype_id]

            donor_meta = []
            agg_df = pd.DataFrame()

            # Get tissue and cell type labels
            tissue_label = subset.obs['tissue'].iat[0] if tissue_agg_colname else None
            celltype_label = subset.obs['cell_type'].iat[0] if celltype_agg_colname else None

            for donor in subset.obs[donor_colname].unique():
                donor_cells = subset[subset.obs[donor_colname] == donor]
                if donor_cells.shape[0] < min_cells:
                    continue

                donor_meta.append({
                    'donorId': donor,
                    'cellCount': donor_cells.shape[0],
                    'sex': donor_cells.obs[sex_colname].iat[0]
                    if sex_colname in donor_cells.obs and len(donor_cells.obs[sex_colname]) > 0
                    else np.nan,
                    'age': donor_cells.obs[age_colname].iat[0]
                    if age_colname in donor_cells.obs and len(donor_cells.obs[age_colname]) > 0
                    else np.nan,
                    'ethnicity': donor_cells.obs[ethnicity_colname].iat[0]
                    if ethnicity_colname in donor_cells.obs and len(donor_cells.obs[ethnicity_colname]) > 0
                    else np.nan,
                })

                matrix = donor_cells.to_df()
                if agg_method == 'mean':
                    vector = matrix.mean(axis=0)
                else:  # sum aggregation
                    vector = matrix.sum(axis=0)
                    # Apply CPM normalization to summed counts
                    vector = self.normalise_counts(vector)
                agg_df[donor] = vector

            if agg_df.empty:
                continue

            agg_df.index.name = 'targetId'
            agg_df.reset_index(inplace=True)

            melted_df = agg_df.melt(id_vars='targetId', var_name='donorId', value_name='expression')
            meta_df = pd.DataFrame(donor_meta)
            merged_df = melted_df.merge(meta_df, on='donorId')

            merged_df['datasourceId'] = self.datasource_id
            merged_df['datatypeId'] = self.datatype_id
            # Set unit based on aggregation method
            unit_dict = {
                'mean': 'pseudobulk mean(logCP10K[counts])',
                'sum': 'CPM(pseudobulk sum[counts])'
            }
            merged_df['unit'] = unit_dict[agg_method]
            merged_df['tissueBiosampleId'] = tissue_id.replace(':', '_') if tissue_agg_colname else None
            merged_df['celltypeBiosampleId'] = celltype_id.replace(':', '_') if celltype_agg_colname else None
            merged_df['tissueBiosampleFromSource'] = tissue_label
            merged_df['celltypeBiosampleFromSource'] = celltype_label

            if merged_df.empty:
                continue

            # instead of appending to all_data, write _this_ merged_df immediately:
            self._save_chunk(merged_df, output_dir)

        logger.info(f'Finished writing JSON to {output_dir}')

    def _save_chunk(self, df: pd.DataFrame, output_dir: str):
        # Make sure the df contains all the right columns and that they are in the right order
        for col in self.flat_schema.fieldNames():
            if col not in df.columns:
                df[col] = None  # Fill missing columns with None
        # Ensure the order of columns matches the schema
        df = df[self.flat_schema.fieldNames()]
        # Lift into Spark
        raw_sdf = self.spark.createDataFrame(df, schema=self.flat_schema)

        # Append into JSON output
        if self.json:
            raw_sdf.write.mode('append') \
                .json(output_dir)
        else:
            # If not JSON, write as parquet
            raw_sdf.write.mode('append') \
                .parquet(output_dir)

        logger.info(f'  â†’ Appended {df.shape[0]} rows into Spark and wrote JSON chunk.')

    def run(self, min_cells, min_genes, technology,
     normalise, aggregation_min_cells, aggregation_method,
     tissue_agg_colname, celltype_agg_colname, age_colname,
     sex_colname, ethnicity_colname, donor_colname):
        self.read_h5ad()
        self.filter_anndata(min_cells, min_genes, technology)

        # Only apply AnnData normalization if the normalise flag is set and using mean aggregation
        if normalise and aggregation_method == 'mean':
            self.normalise_anndata()

        # Run pseudobulking for tissue, celltype, and both
        aggregation_configs = []
        if tissue_agg_colname:
            aggregation_configs.append({'tissue_agg_colname': tissue_agg_colname,
                                        'celltype_agg_colname': None})
        if celltype_agg_colname:
            aggregation_configs.append({'celltype_agg_colname': celltype_agg_colname,
                                        'tissue_agg_colname': None})
        if tissue_agg_colname and celltype_agg_colname:
            aggregation_configs.append({'tissue_agg_colname': tissue_agg_colname,
                                        'celltype_agg_colname': celltype_agg_colname})

        for config in aggregation_configs:
            self.pseudobulk_data(
                donor_colname,
                aggregation_min_cells,
                tissue_agg_colname=config['tissue_agg_colname'],
                celltype_agg_colname=config['celltype_agg_colname'],
                age_colname=age_colname,
                sex_colname=sex_colname,
                ethnicity_colname=ethnicity_colname,
                agg_method=aggregation_method
            )
        logger.info('All done.')
